# ğŸ“° Article Topic Classification â€“ Production-Style NLP System

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-red.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/Transformers-4.0%2B-brightgreen.svg)](https://huggingface.co/transformers/)

A production-oriented **end-to-end NLP system** that classifies news articles into four topics using a fineâ€‘tuned **DistilBERT** model.
This project goes beyond model training and demonstrates **real industry ML practices**: clean data pipelines, proper evaluation, confidenceâ€‘aware decision logic, batch processing, and a deployable FastAPI service.

---

## ğŸ¯ Problem Statement

Given a news article (title + body), automatically predict its primary topic:

* **World**
* **Sports**
* **Business**
* **Sci/Tech**

The system must also:

* Return a confidence score
* Expose probabilities for all classes
* Decide whether a prediction can be autoâ€‘accepted or needs human review

---

## âœ¨ Key Features

* **Modern Transformer Model**: Fineâ€‘tuned DistilBERT (fast, lightweight, productionâ€‘friendly)
* **Endâ€‘toâ€‘End ML Lifecycle**: Data â†’ Training â†’ Evaluation â†’ Inference â†’ API
* **Confidenceâ€‘Aware Decisions**: Autoâ€‘accept / Needsâ€‘review / Reject logic
* **Batch Inference Support**: Process large article sets efficiently
* **FastAPI Service**: Deployable REST API with modern ASGI lifespan handling
* **GPUâ€‘Accelerated Training**: PyTorch + CUDA

---

## ğŸ§  Why DistilBERT?

DistilBERT retains ~95% of BERTâ€™s accuracy while being ~40% smaller and ~60% faster.

**Chosen because:**

* Strong pretrained language understanding
* Lower latency and cost than full BERT
* Widely used in real production NLP systems
* Excellent fit for topic classification

---

## ğŸ—ï¸ System Architecture

```
Raw Data (CSV)
   â†“
Data Conversion Pipeline
(CSV â†’ XML / JSONL / Parquet)
   â†“
Train / Validation / Test Split
   â†“
Model Training (DistilBERT)
   â†“
Evaluation on Unseen Data
   â†“
Inference Layer
   â”œâ”€ Single Prediction
   â”œâ”€ Batch Inference
   â””â”€ FastAPI Service
```

---

## ğŸ“ Project Structure

```
article-topic-classifier/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ app.py              # FastAPI service
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ distilbert/         # Trained model & tokenizer
â”œâ”€â”€ config/
â”‚   â””â”€â”€ train.yaml          # Training configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl
â”‚   â”œâ”€â”€ val.jsonl
â”‚   â””â”€â”€ test.jsonl
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_sanity_check.py
â”‚   â”œâ”€â”€ split_dataset.py
â”‚   â”œâ”€â”€ train_distilbert.py
â”‚   â”œâ”€â”€ evaluate_distilbert.py
â”‚   â”œâ”€â”€ predict.py          # Single inference
â”‚   â””â”€â”€ batch_predict.py    # Batch inference
â”œâ”€â”€ src/
â”‚   â””â”€â”€ dataset.py          # PyTorch Dataset
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ training_*.log
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ” Confidenceâ€‘Aware Decision Logic

Predictions are not blindly trusted. The system applies routing rules:

* **auto_accept**

  * confidence â‰¥ 0.85
  * topâ€‘1 vs topâ€‘2 probability gap â‰¥ 0.20

* **needs_review**

  * confidence â‰¥ 0.60 but ambiguous

* **reject**

  * confidence < 0.60

This mirrors how real editorial and enterprise ML systems manage risk.

---

## ğŸš€ Training

```bash
python -m scripts.train_distilbert
```

* Uses GPU if available
* Trains DistilBERT for topic classification
* Saves model and tokenizer to `artifacts/distilbert/`

---

## ğŸ“Š Evaluation

```bash
python -m scripts.evaluate_distilbert
```

Evaluation is performed on **unseen test data** and reports:

* Accuracy
* Precision / Recall / F1 per class
* Confusion matrix
* Confidence statistics

**Example result:** ~90% accuracy with balanced class performance.

---

## ğŸ§ª Inference

### Single Article

```bash
python -m scripts.predict
```

Returns:

* predicted topic
* confidence
* probabilities for all classes
* decision (auto_accept / needs_review / reject)

### Batch Inference

```bash
python -m scripts.batch_predict
```

Processes an entire JSONL file and produces a JSONL output with predictions and decisions for each article.

---

## ğŸŒ API Service (FastAPI)

Run the API:

```bash
uvicorn api.app:app --reload
```

Endpoints:

* `POST /predict` â€” single article
* `POST /batch_predict` â€” multiple articles

Interactive docs:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ› ï¸ Tech Stack

* Python
* PyTorch
* Hugging Face Transformers
* DistilBERT
* FastAPI
* scikitâ€‘learn
* JSONL / Parquet

---

## âœ… What This Project Demonstrates

* Clean separation of data, model, and serving layers
* Proper train/validation/test isolation
* Confidenceâ€‘aware ML decision making
* Batch vs realâ€‘time inference patterns
* Productionâ€‘ready API design

---

## ğŸ”® Future Extensions (V2 Ideas)

* Vector embeddings for semantic search
* LLM (LLaMA) integration for summarization
* Model monitoring & drift detection
* Dockerized deployment

---

## ğŸ“„ License

MIT License

---

## Summary

This repository demonstrates how to build a **realistic, productionâ€‘ready NLP system**, not just a model. It reflects how modern ML is designed, evaluated, and served in industry.
